# Abstractive-Text-Summarization-using-RLHF

After trying abstractive text summarization with finetuned Pegasus transformer, I was motivated by the latest concept of a human-in-the-loop model delivering SOTA results in several NLP tasks.
So I explored this Abstractive Text Summarization task using a finetuned LLaMa-2 model and optimized it further through Proximal Policy Optimization(a concept I learnt in my reinforcement learning class) by feeding human-labelled scores to a reward model.
This project is still in progress. Will take a while to be fully developed.

Up next - Neural Machine Translation using RLHF!
